{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b5060f",
   "metadata": {},
   "source": [
    "# Import and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54cbea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mushj\\anaconda3\\envs\\fin_mod_env\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a919acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"C:/Users/mushj/Downloads/PROCESSED FINANCE DATA/\"\n",
    "OUTPUT_PATH = INPUT_PATH\n",
    "\n",
    "SOURCE_COL = 'Lsa_summary'\n",
    "CLEANED_COL = 'Lsa_summary_cleaned'\n",
    "\n",
    "REP_METHOD = 'TF-IDF'\n",
    "# REP_METHOD = 'BoW'\n",
    "# MODEL = 'LDA'\n",
    "MODEL = 'NMF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fbe67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8716, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH+\"FNSPID_NVDA_cleaned.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b369b28",
   "metadata": {},
   "source": [
    "# Numerical representation of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2b8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DF = 0.75\n",
    "MIN_DF = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460a3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one representation for the next step.\n",
    "if REP_METHOD == 'TF-IDF':\n",
    "    vectorizer = TfidfVectorizer(max_df=MAX_DF, min_df=MIN_DF, stop_words='english')\n",
    "    text_matrix = vectorizer.fit_transform(df[CLEANED_COL])\n",
    "else:\n",
    "    vectorizer = CountVectorizer(max_df=MAX_DF, min_df=MIN_DF, stop_words='english')\n",
    "    text_matrix = vectorizer.fit_transform(df[CLEANED_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57aa2e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8716x129 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 129924 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9214c",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f318a",
   "metadata": {},
   "source": [
    "## - Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b51e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 20  # Number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf358cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.91 s\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if MODEL == 'LDA':\n",
    "    # Latent Dirichlet Allocation (LDA)\n",
    "    model = LatentDirichletAllocation(n_components=N_TOPICS, random_state=42)\n",
    "    topics = model.fit_transform(text_matrix)\n",
    "elif MODEL == 'NMF':\n",
    "    # Non-Negative Matrix Factorization (NMF)\n",
    "    model = NMF(n_components=N_TOPICS, random_state=42)\n",
    "    topics = model.fit_transform(text_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a580a",
   "metadata": {},
   "source": [
    "## - Analyze topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5844a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top words per topic\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    \"\"\"Returns a list of strings that summarizes the words that make up each topic.\n",
    "    \"\"\"\n",
    "    topics = []\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topics.append(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e77172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "topics_to_display = display_topics(model, feature_names, no_top_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56046d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: company, like, business, make, technology\n",
      "Topic 2: free, report, analysis, stock, click\n",
      "Topic 3: rate, federal, reserve, wall, street\n",
      "Topic 4: stock, nasdaqnvda, nvda, source, market\n",
      "Topic 5: fool, motley, video, decade, run\n",
      "Topic 6: amd, device, advanced, micro, intel\n",
      "Topic 7: etf, research, holding, report, sp\n",
      "Topic 8: trading, share, month, today, far\n",
      "Topic 9: nvda, corp, growth, industry, computer\n",
      "Topic 10: chip, said, reuters, nvdao, china\n",
      "Topic 11: earnings, zacks, nvda, estimate, share\n",
      "Topic 12: meta, platform, microsoft, alphabet, apple\n",
      "Topic 13: graphic, unit, processing, gpus, gaming\n",
      "Topic 14: fund, average, nvda, nasdaqnvda, report\n",
      "Topic 15: nasdaq, nvda, video, stock, market\n",
      "Topic 16: data, center, revenue, nvidias, gaming\n",
      "Topic 17: ai, artificial, intelligence, chip, cloud\n",
      "Topic 18: analyst, price, share, buy, higher\n",
      "Topic 19: semiconductor, industry, giant, demand, global\n",
      "Topic 20: year, market, past, time, gain\n"
     ]
    }
   ],
   "source": [
    "# Print topics\n",
    "for topic in topics_to_display:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f041f",
   "metadata": {},
   "source": [
    "## - Analyze topics distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d9ca9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8716, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77226d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "dominant_topics = np.argmax(topics, axis=1)\n",
    "df['topic'] = dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "045922b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "0     0.000115\n",
       "1     0.151790\n",
       "2     0.095801\n",
       "3     0.027077\n",
       "4     0.039009\n",
       "5     0.019849\n",
       "6     0.012735\n",
       "7     0.022487\n",
       "8     0.023520\n",
       "9     0.034305\n",
       "10    0.031207\n",
       "11    0.040730\n",
       "12    0.051514\n",
       "13    0.018701\n",
       "14    0.060808\n",
       "15    0.056333\n",
       "16    0.102226\n",
       "17    0.077214\n",
       "18    0.071592\n",
       "19    0.062988\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53bc66",
   "metadata": {},
   "source": [
    "## - Sample text to topic mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3700ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 13: graphic, unit, processing, gpus, gaming \n",
      "\n",
      "Stock splits, meanwhile, continue to get attention from investors after nearly every big tech stock split its shares in 2021 and 2022, including Tesla, Apple, Alphabet, Amazon, Nvidia (NASDAQ: NVDA), and Shopify. The launch of OpenAI's ChatGPT in late 2022 set off a new race to harness generative AI technologies, which some tech CEOs think could be as transformative as the internet has been over the past three decades. Its graphics processing units (GPUs) and accelerators have been in high demand from cloud infrastructure companies and others looking to scale up and build capacity for AI applications.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "row = df.iloc[i]\n",
    "print(topics_to_display[row['topic']], '\\n')\n",
    "print(row[SOURCE_COL])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
